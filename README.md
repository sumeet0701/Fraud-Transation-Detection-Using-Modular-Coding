# Fraud Transaction Detection:

A modularized system to detect fraudulent transactions, built with clean architecture and scalable design.

---

## Table of Contents

- [Problem Statement](#problem-statement)  
- [Key Features](#key-features)  
- [Architecture & Process Flow](#architecture--process-flow)  
- [Project Structure](#project-structure)  
- [Technologies Used](#technologies-used)  
- [Installation & Setup](#installation--setup)  
- [Usage](#usage)  
- [Model Training & Prediction Workflow](#model-training--prediction-workflow)  
- [Docker & Deployment](#docker--deployment)  
- [Monitoring & MLOps](#monitoring--mlops)  
- [Contributing](#contributing)  
- [License & Author](#license--author)  

---

## Problem Statement

With increasing digital transactions, detecting fraudulent activity in real time is critical for financial safety. This project aims to determine whether transactions are fraudulent using a modular, scalable pipeline.

---

## Key Features

- **Modular Design**: Organized into components for data ingestion, preprocessing, validation, model training, prediction, and logging.
- **Supports Real-Time & Batch Prediction**: Use for single prediction inputs or batch processing via API or CLI.
- **Model Training Pipeline**: Automates training and selecting the best model version.
- **Monitoring & Logging**: Captures validation logs and tracks model performance.
- **Deployment Friendly**: Can be containerized via Docker and deployed with ease.
- **MLOps Support**: Integrated with DVC and MLflow for experiment tracking and pipeline orchestration.

---

## Architecture & Process Flow

```mermaid
flowchart TD
    A[Data Ingestion] --> B[Data Preprocessing & Validation]
    B --> C[Model Training & Best Model Selection]
    C --> D[Model Registry / Tracking]
    B --> E[Prediction Module â†’ Single / Batch]
    E --> F[API / CLI Interface]
    C & E --> G[Logging & Monitoring System]
```

## Project Structure:
```
Fraud-Transation-Detection-Using-Modular-Coding/
â”œâ”€â”€ Application_Logging/
â”œâ”€â”€ Data_Ingestion/
â”œâ”€â”€ Data_Preprocessing/
â”œâ”€â”€ Dataset/
â”œâ”€â”€ File_Operations/
â”œâ”€â”€ best_model_finder/
â”œâ”€â”€ models/                          # Contains saved models (e.g., XGBoost)
â”œâ”€â”€ PredictionArchiveBadData_AdditionalFile/
â”œâ”€â”€ PredictionFileFromDB/
â”œâ”€â”€ Prediction_Batch_Files/
â”œâ”€â”€ Prediction_DataType_Validation/
â”œâ”€â”€ Prediction_Data_Preprocessing_BeforeDB/
â”œâ”€â”€ Prediction_Database/
â”œâ”€â”€ Prediction_Logs/
â”œâ”€â”€ Prediction_Output_File/
â”œâ”€â”€ Prediction_Raw_Data_Validation/
â”œâ”€â”€ TrainingArchiveBadData_AdditionalFile/
â”œâ”€â”€ TrainingFileFromDB/
â”œâ”€â”€ Training_Batch_Files/
â”œâ”€â”€ Training_DataType_Validation/
â”œâ”€â”€ Training_Data_Preprocessing_BeforeDB/
â”œâ”€â”€ Training_Database/
â”œâ”€â”€ Training_Raw_Data_Validation/
â”œâ”€â”€ TrainingModel.py
â”œâ”€â”€ training_validation_insertion.py
â”œâ”€â”€ prediction_validation_insertion.py
â”œâ”€â”€ app.py                          # Flask web app for real-time usage
â”œâ”€â”€ predict_from_model.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ runtime.txt
â”œâ”€â”€ Procfile / app.yaml / manifest.yml  # For platform deployments
â”œâ”€â”€ templates/                      # If thereâ€™s an HTML interface
â”œâ”€â”€ schema_Training.json
â”œâ”€â”€ schema_Prediction.json
â””â”€â”€ assets/                         # Contains visuals like flowchart & UI previews
-----
```

## Technologies Used:
- **Python** â€“ Primary programming language
- **Machine Learning** â€“ XGBoost or equivalen
- **API Framework** â€“ Flask for web interface
- **MLOps Tools** â€“ DVC & MLflow for tracking and experiment management
- **Deployment** â€“ Docker, plus optional Heroku or other cloud platforms
- **Database / Storage** â€“ Optional use of MongoDB or structured files for logs or storage

## ðŸš€ Installation & Setup

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/sumeet0701/Fraud-Transation-Detection-Using-Modular-Coding.git](https://github.com/sumeet0701/Fraud-Transation-Detection-Using-Modular-Coding.git)
    cd Fraud-Transation-Detection-Using-Modular-Coding
    ```

2.  **Create your Python environment and install dependencies:**
    ```bash
    conda create -n fraud_env python=3.6.9
    conda activate fraud_env
    pip install -r requirements.txt
    ```

---

## ðŸ’» Usage

### Single Transaction Prediction

Run the `app.py` script to get a prediction for a single transaction via a web API.
```bash
python app.py
```

### For Batch Process:
For large datasets, use the predict_from_model.py script for batch predictions.
```bash
python predict_from_model.py --input_file path/to/data.csv --output_file path/to/predictions.csv
```
## Model Training & Prediction Workflow
- **Training Model**: Run ```TrainingModel.py``` to preprocess, train, and select the best model.
- **Model Tracking**: Use DVC and MLflow to version and monitor models.
- **Prediction:** Uses ```predict_from_model.py``` for batch predictions, or the API via ```app.py```.

-------

## Docker & Deployment
### Docker:
```bash

FROM python:3.9-slim
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
EXPOSE 5000
CMD ["python", "app.py"]
```
### Deploy:
Build and run locally:
```bash
docker build -t fraud-detector .
docker run -p 5000:5000 fraud-detector
```
- Suitable for deployment to platforms like Heroku, GCP, AWS, etc.

## Monitoring & MLOps
- Flask Monitoring Dashboard: Optional UI to inspect API performance.
- Logging: Stored in Prediction_Logs/ and Training_Logs/.
- Model Registry: Use MLflow to compare versions and performance metrics.

## Contributing
- Fork the repo
  -- Create a feature branch: git checkout -b feature/YourFeature
  -- Commit your changes: git commit -m "Add new feature"
  -- Push and open a Pull Request

## License & Author

License: MIT License (see LICENSE file)

Author: @Maheshwari Sumeet
